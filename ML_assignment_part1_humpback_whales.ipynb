{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89c684ed",
   "metadata": {},
   "source": [
    "# Image Classification ML Assignment \n",
    "\n",
    "#### In this jupyter notebook, you will modify and run a machine learning model to classify humpback whale individuals. This script has several functions that are written for you, please do NOT modify any code unless it specifies to change it. \n",
    "\n",
    "#### Training the first model will take roughly 10 minutes. Although there are questions throughout this file, it is prudent to begin training your model before answering these questions. Once the model has begun training, explore the structure of the image folders, consider what each box of code is doing, and answer the questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dc4335-2123-4a48-b896-2f943f1a20b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing packages - Please DO NOT alter this box ##\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import DeepLift\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()\n",
    "\n",
    "import os\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage import binary_erosion\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "#import wandb #remove comment if you are using weights and biases\n",
    "#import random #remove comment if you are using weights and biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534ef932",
   "metadata": {},
   "source": [
    "**What is the goal of transforming the data set?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4148cd12",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d35c66-3147-442b-9235-b9e3551a06d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = \"/projects/bgmp/shared/Bi625/ML_Assignment/Datasets/Humpback_ML_set/Humpback_ML_set\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfa4b0-aecb-4789-98a0-b3568b078bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.Resize([224,224]), # Resizing the image as the VGG only take 224 x 244 as input size\n",
    "            transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize the data, these are the values that ResNet suggests based on their training data (natural scences)\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 1)),\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
    "    transforms.RandomHorizontalFlip()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e84ad1a",
   "metadata": {},
   "source": [
    "The below code completes the image transformations as coded in the above box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d3cb05-efe7-4910-8d15-bacf4abe5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images = datasets.ImageFolder(images, transform )\n",
    "print(len(all_images))\n",
    "print(all_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6881500f",
   "metadata": {},
   "source": [
    "The below code eastablishes the data split between training, validation, and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7a7944-26ec-4d9e-af09-7b7a375a58cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.7 * len(all_images))\n",
    "val_size = int(0.15 * len(all_images))\n",
    "test_size = len(all_images) - (train_size + val_size)\n",
    "print(train_size, val_size, test_size)\n",
    "assert train_size + val_size + test_size == len(all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5770b4-a029-4dc6-b948-c0b16b4a6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, val_set, test_set = torch.utils.data.random_split(all_images, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a35d904",
   "metadata": {},
   "source": [
    "The below function is used to get weights for the image classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6879d27a-063d-4ff0-9769-68b13cf5787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_weights(subset,full_dataset):\n",
    "    ys = np.array([y for _, y in subset])\n",
    "    counts = np.bincount(ys)\n",
    "    label_weights = 1.0 / counts\n",
    "    weights = label_weights[ys]\n",
    "\n",
    "    print(\"Number of images per class:\")\n",
    "    for c, n, w in zip(full_dataset.classes, counts, label_weights):\n",
    "        print(f\"\\t{c}:\\tn={n}\\tweight={w}\")\n",
    "        \n",
    "    return weights\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549c6341",
   "metadata": {},
   "source": [
    "The below function is used to randomly select dataset images to evaluate how the transformations altered the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb73b9b6-d4dc-4a68-85af-8a0e51aeda7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_dataset_image(dataset):\n",
    "    idx = np.random.randint(0, len(dataset))    # take a random sample\n",
    "    img, mask = dataset[idx]                    # get the image and the nuclei masks\n",
    "    f, axarr = plt.subplots(1, 2)               # make two plots on one figure\n",
    "    axarr[0].imshow(img[0], cmap=\"gist_ncar\")                     # show the image, cmap is the color map that the image is being shown in\n",
    "    #axarr[1].imshow(mask[0])                    # show the masks\n",
    "    _ = [ax.axis('off') for ax in axarr]        # remove the axes\n",
    "    print('Image size is %s' % {img[0].shape})\n",
    "    print(img.shape)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d042e5",
   "metadata": {},
   "source": [
    "**What is the difference between image size and torch image size?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04154971",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a8896a-3108-4eb5-945c-3a8f10cce45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_dataset_image(train_set)\n",
    "show_random_dataset_image(train_set)\n",
    "show_random_dataset_image(train_set)\n",
    "show_random_dataset_image(train_set)\n",
    "\n",
    "\n",
    "show_random_dataset_image(val_set)\n",
    "show_random_dataset_image(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0424fa16",
   "metadata": {},
   "source": [
    "**Add a new transformation to the training data and discuss how it modifies the images.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dc3839",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc743bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "            transforms.Resize([224,224]), # Resizing the image as the VGG only take 224 x 244 as input size\n",
    "            transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # Normalize the data, these are the values that ResNet suggests based on their training data (natural scences)\n",
    "            transforms.RandomRotation(10),\n",
    "            transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 1)),\n",
    "    transforms.ColorJitter(brightness=0.05, contrast=0.05),\n",
    "    transforms.RandomHorizontalFlip()])\n",
    "\n",
    "all_images = datasets.ImageFolder(images, transform )\n",
    "\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(all_images, [train_size, val_size, test_size])\n",
    "\n",
    "show_random_dataset_image(train_set)\n",
    "show_random_dataset_image(train_set)\n",
    "show_random_dataset_image(train_set)\n",
    "show_random_dataset_image(train_set)\n",
    "show_random_dataset_image(val_set)\n",
    "show_random_dataset_image(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04213e8-cece-448f-b0cf-365b5e491bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_weights = _get_weights(train_set,all_images)\n",
    "train_sampler = WeightedRandomSampler(train_weights, len(train_weights))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf1a223",
   "metadata": {},
   "source": [
    "**When the class weight is calculated by WeightedRandomSampler what is it used for in the training of a model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc5fb2a-6c5b-4b1d-9a86-fefdf5114706",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Hint</summary>\n",
    "  \n",
    "Check out this resource: https://towardsdatascience.com/demystifying-pytorchs-weightedrandomsampler-by-example-a68aceccb452 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0258c",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad00a825-883d-4dbf-803e-5474a5929c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=12, drop_last=True, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_set, batch_size=12, drop_last=True, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=12, drop_last=True, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3a4fb8",
   "metadata": {},
   "source": [
    "**What is resnet18?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f66cb3-eaf8-46de-984a-c99ca229c839",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary> Hint </summary>\n",
    "  \n",
    " Check out this website: https://www.geeksforgeeks.org/resnet18-from-scratch-using-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b985fbb3",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cddabe4-9dbc-4a33-bb01-106e94c9dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_model = torchvision.models.resnet18(weights = False, progress  = True, num_classes=5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet18_model.parameters(), lr=0.001)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet18_model.to(device)\n",
    "print(f\"Will use device {device} for training\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d700e6a2",
   "metadata": {},
   "source": [
    "The below functions are used to train, evaluate, and test the Machine Learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0a3ba8-b030-4e75-b534-334462a1b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,loss,train_dataloader):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    num_batches = 0\n",
    "    for x, y in tqdm(train_dataloader):\n",
    "\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        y_pred = model(x)\n",
    "        l = loss(y_pred, y)\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += l\n",
    "        num_batches += 1\n",
    "\n",
    "    return epoch_loss/num_batches\n",
    "\n",
    "def evaluate(model, loss, dataloader):\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in tqdm(dataloader):\n",
    "\n",
    "            x, y = x.to(device), y.to(device)\n",
    "\n",
    "            logits = model(x)\n",
    "            val_loss = loss(logits,y)\n",
    "            \n",
    "            probs = torch.nn.Softmax(dim=1)(logits)\n",
    "            predictions = torch.argmax(probs, dim=1)\n",
    "\n",
    "            correct += int(torch.sum(predictions == y).cpu().detach().numpy())\n",
    "            total += len(y)\n",
    "\n",
    "        accuracy = correct/total\n",
    "\n",
    "    return accuracy, val_loss\n",
    "\n",
    "def validate(model,loss, validation_dataloader):\n",
    "    '''Evaluate prediction accuracy on the validation dataset.'''\n",
    "    \n",
    "    model.eval()\n",
    "    return evaluate(model,loss,validation_dataloader)\n",
    "\n",
    "def test(model,loss,test_dataloader):\n",
    "    '''Evaluate prediction accuracy on the test dataset.'''\n",
    "    \n",
    "    model.eval() \n",
    "    return evaluate(model, loss,test_dataloader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d79c89",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8641b2c5",
   "metadata": {},
   "source": [
    "#### Start with 10 epochs, run the below model and consider the success of the model training. \n",
    "\n",
    "**What is your starting accuracy and final accuracy? Why is there a difference between the two?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebff257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(\n",
    "#     project=\"Humpback-classification-project\",\n",
    "#     name=\"Humpback-training-run-preset-hyperparameters\",\n",
    "#     config={\"learning rate\":0.001,\n",
    "#         \"architecture\": \"CNN\",\n",
    "#         \"dataset\": \"Humpback\",\n",
    "#         \"epochs\":10}\n",
    "# ) ### Remove comments if using weights and biases\n",
    "\n",
    "###\n",
    "step = 0\n",
    "epochs = 10\n",
    "\n",
    "validation_accuracy_list = []\n",
    "validation_loss_list = []\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    while step < epoch: \n",
    "    \n",
    "        epoch_loss = train(resnet18_model,loss_fn,train_loader)\n",
    "        print(f\"epoch {epoch}, training loss={epoch_loss}\")\n",
    "    \n",
    "        validation_accuracy, validation_loss = validate(resnet18_model, loss_fn,val_loader)\n",
    "        validation_accuracy_list.append(validation_accuracy)\n",
    "        validation_loss_list.append(validation_loss)\n",
    "        print(f\"epoch {epoch}, validation accuracy={validation_accuracy}\")\n",
    "        \n",
    "        # log metrics to wandb - remove comments if using weights and biases\n",
    "        #wandb.log({\"validation_accuracy\": validation_accuracy, \"validation_loss\": validation_loss, \"epoch_loss\":epoch_loss})\n",
    "\n",
    "        step += 1\n",
    "\n",
    "plt.plot(range(10), validation_accuracy_list, color = \"magenta\")\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Valiation accuracy\")\n",
    "plt.show()  \n",
    "\n",
    "plt.plot(range(10), validation_loss_list, color = \"purple\")\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Valiation loss\")\n",
    "plt.show()  \n",
    "\n",
    "#wandb.finish() #remove comments if using weights and biases\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ec6595",
   "metadata": {},
   "source": [
    "After running the model and calculating the overall accuracy, we can examine the data via a confusion matrix which highlights the accuracy by class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdebebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test dataset\n",
    "def predict(model, dataset):\n",
    "    dataset_prediction = []\n",
    "    dataset_groundtruth = []\n",
    "    model = model\n",
    "    with torch.no_grad():\n",
    "        for x, y_true in dataset:\n",
    "            inp = x[None]\n",
    "            y_pred = model(inp)\n",
    "            dataset_prediction.append(y_pred.argmax().cpu().numpy())\n",
    "            dataset_groundtruth.append(y_true)\n",
    "    \n",
    "    return np.array(dataset_prediction), np.array(dataset_groundtruth)\n",
    "            \n",
    "    # create seaborn heatmap with required labels\n",
    "    ax=sns.heatmap(cm, annot=annot, fmt='', vmax=30, xticklabels=x_axis_labels, yticklabels=y_axis_labels)\n",
    "    ax.set_title(title)\n",
    "\n",
    "# Plot confusion matrix \n",
    "# orginally from Runqi Yang; \n",
    "# see https://gist.github.com/hitvoice/36cf44689065ca9b927431546381a3f7\n",
    "def cm_analysis(y_true, y_pred, title, figsize=(10,10)):\n",
    "    \"\"\"\n",
    "    Generate matrix plot of confusion matrix with pretty annotations.\n",
    "    The plot image is saved to disk.\n",
    "    args: \n",
    "      y_true:    true label of the data, with shape (nsamples,)\n",
    "      y_pred:    prediction of the data, with shape (nsamples,)\n",
    "      filename:  filename of figure file to save\n",
    "      labels:    string array, name the order of class labels in the confusion matrix.\n",
    "                 use `clf.classes_` if using scikit-learn models.\n",
    "                 with shape (nclass,).\n",
    "      ymap:      dict: any -> string, length == nclass.\n",
    "                 if not None, map the labels & ys to more understandable strings.\n",
    "                 Caution: original y_true, y_pred and labels must align.\n",
    "      figsize:   the size of the figure plotted.\n",
    "    \"\"\"\n",
    "    labels = ['new_whale','w_0369a5c', 'w_23a388d', 'w_9b5109b', 'w_9c506f6']\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "                              \n",
    "    x_axis_labels = ['new_whale','w_0369a5c', 'w_23a388d', 'w_9b5109b', 'w_9c506f6'] # labels for x-axis\n",
    "    y_axis_labels = ['new_whale','w_0369a5c', 'w_23a388d', 'w_9b5109b', 'w_9c506f6'] # labels for y-axis\n",
    "    ax=sns.heatmap(cm, annot=annot, fmt='', vmax=30, xticklabels=x_axis_labels, yticklabels=y_axis_labels, cmap = \"viridis\")\n",
    "    ax.set_title(title)\n",
    "\n",
    "## This plot only contains the test set of data\n",
    "## The test set of data has not been seen by the model yet\n",
    "y_pred, y_true = predict(resnet18_model, test_set)\n",
    "cm_analysis(y_true, y_pred, \"Confusion matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac36bf3a-bb62-4786-b264-5098db37602f",
   "metadata": {},
   "source": [
    "Since the dataset is small, we can also manually look at the true and predicted classifications for our test dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019cfa35-0fea-4e80-9970-37971e9d5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred, test_true = predict(resnet18_model, test_set)\n",
    "print(test_pred)\n",
    "print(test_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ce810",
   "metadata": {},
   "source": [
    "### What features did the model use to make decisions?\n",
    "\n",
    "Based on the confusion matrices and validation loss, it is clear that the model is learning. To determine the features that are involved in decision making, there are a few possible approaches. Two options are shown below, integrated gradients and CycleGAN. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc1a543",
   "metadata": {},
   "source": [
    "#### Understanding feature importance using Integrated Gradients\n",
    "\n",
    "Integrated gradients is an attribution method. Attribution methods score the input data based on the prediction that the model makes using scores for each feature. The gradient is the signal that tells the network how much to increase or decrease a certain weight in the network during backpropogation. These gradients are overlaid onto the images to showcase the regions on the images that influence the weights.\n",
    "\n",
    "**Run the below code. Does the integrated gradient show what types of features the model used to classify the images? What have you learned from it?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b40850",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae68173",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_ig(idx, \n",
    "                 _train_dataset=train_set, \n",
    "                 _test_dataset=test_set):\n",
    "        \n",
    "    # Get corresponding input and target tensors:\n",
    "    input_tensor = _test_dataset[idx][0].unsqueeze(0)\n",
    "    input_tensor.requires_grad = True\n",
    "    target = _test_dataset[idx][1]\n",
    "    \n",
    "    # We will use the IntegratedGradients algorithm:\n",
    "    algorithm = IntegratedGradients(resnet18_model)\n",
    "    \n",
    "    # First we clear the gradients from the model:\n",
    "    resnet18_model.zero_grad()\n",
    "    \n",
    "    # Run attribution:\n",
    "    attr_ig, delta = algorithm.attribute(input_tensor,\n",
    "                                          target=target,\n",
    "                                          baselines=input_tensor * 0,\n",
    "                                          return_convergence_delta=True\n",
    "                                        )\n",
    "    \n",
    "    # Integrated Gradients:\n",
    "    attr_ig = np.transpose(attr_ig[0].cpu().detach().numpy(), (1, 2, 0))\n",
    "    \n",
    "    # Original image:\n",
    "    original_image = np.transpose((_test_dataset[idx][0].detach().numpy() * 0.5) + 0.5, (1, 2, 0))\n",
    "    \n",
    "    print(\"Annotated Whale Individual\", test_true[idx])\n",
    "    plt.imshow(original_image)\n",
    "    \n",
    "    \n",
    "    print(\"Predicted Whale Individual\", test_pred[idx])\n",
    "\n",
    "\n",
    "    # This visualises the attribution of labels to \n",
    "    viz.visualize_image_attr(attr_ig, \n",
    "                             original_image, \n",
    "                             method=\"blended_heat_map\",\n",
    "                             sign=\"all\",\n",
    "                             show_colorbar=True, \n",
    "                             title=\"Overlayed Integrated Gradients\")\n",
    "\n",
    "visualize_ig(0)\n",
    "\n",
    "visualize_ig(8)\n",
    "\n",
    "visualize_ig(20)\n",
    "\n",
    "visualize_ig(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25173115",
   "metadata": {},
   "source": [
    "## Code and Explore! \n",
    "\n",
    "Now that you have a sense for how to train a machine learning model, your task is to improve the success of our classification model.\n",
    "\n",
    "**Make one (or more) modifications to the model training process, re-train the model, and report out your changes and whether they increased model accuracy. Do you have ideas why your modifications were/were not successful?**\n",
    "\n",
    "Types of changes that you can make include changing the model, the number of epochs, the optimizer, loss function, learning rate, batch size, image transformations, and more. If you decide to change any lines of code that are not in the below box, please add them to the box (DO NOT MODIFY ANY CODE ABOVE THIS MARKDOWN BOX). \n",
    "\n",
    "If your changes are ambitious, the code may take hours to run. If this is the case, please consider turning this notebook into a python script and running it via sBATCH. \n",
    "\n",
    "**Please note, you will NOT be graded by the success of your classifier! It is okay if you are unable to improve the accuracy of the classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94c4d40",
   "metadata": {},
   "source": [
    "*Put your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06de5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=12, drop_last=True, sampler=train_sampler)\n",
    "val_loader = DataLoader(val_set, batch_size=12, drop_last=True, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=12, drop_last=True, shuffle=True)\n",
    "\n",
    "resnet18_model = torchvision.models.resnet18(weights = False, progress  = True, num_classes=5)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet18_model.parameters(), lr=0.001) #possibly update\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "resnet18_model.to(device)\n",
    "print(f\"Will use device {device} for training\")\n",
    "\n",
    "# wandb.init(\n",
    "#     project=\"Humpback-classification-project\",\n",
    "#     name=\"Humpback-training-run-student-selected-hyperparameters\", ##update this with your first initial and last name\n",
    "#     config={\"learning rate\":.001, # possibly update\n",
    "#         \"architecture\": \"CNN\",\n",
    "#         \"dataset\": \"Humpback\",\n",
    "#         \"epochs\": 10}  # possibly update\n",
    "# ) ##Remove comments if using weights and biases\n",
    "\n",
    "\n",
    "\n",
    "step = 0\n",
    "epochs = 10 # possibly update\n",
    "\n",
    "validation_accuracy_list = []\n",
    "validation_loss_list = []\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "    while step < epoch: \n",
    "    \n",
    "        epoch_loss = train(resnet18_model,loss_fn,train_loader)\n",
    "        print(f\"epoch {epoch}, training loss={epoch_loss}\")\n",
    "    \n",
    "        validation_accuracy, validation_loss = validate(resnet18_model, loss_fn,val_loader)\n",
    "        validation_accuracy_list.append(validation_accuracy)\n",
    "        validation_loss_list.append(validation_loss)\n",
    "        print(f\"epoch {epoch}, validation accuracy={validation_accuracy}\")\n",
    "    \n",
    "        # log metrics to wandb - remove comments if using weights and biases\n",
    "        #wandb.log({\"validation_accuracy\": validation_accuracy, \"validation_loss\": validation_loss, \"epoch_loss\":epoch_loss})\n",
    "\n",
    "        step += 1\n",
    "\n",
    "\n",
    "#wandb.finish() #remove comments if using weights and biases\n",
    "\n",
    "plt.plot(range(10), validation_accuracy_list, color = \"magenta\")\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Valiation accuracy\")\n",
    "plt.show()  \n",
    "\n",
    "plt.plot(range(10), validation_loss_list, color = \"purple\")\n",
    "plt.xlabel(\"Epoch number\")\n",
    "plt.ylabel(\"Valiation loss\")\n",
    "plt.show()  \n",
    "\n",
    "y_pred, y_true = predict(resnet18_model, test_set)\n",
    "cm_analysis(y_true, y_pred, \"Confusion matrix\")\n",
    "\n",
    "## Integrated gradient \n",
    "visualize_ig(0)\n",
    "visualize_ig(8)\n",
    "visualize_ig(20)\n",
    "visualize_ig(32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
